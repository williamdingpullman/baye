## Markov chains

### Definition

A sequence of random variable $X_1, X_2,...,X_n$, with $1, 2, ...,3$ indicating the successitve points in time. Thus, based on the chain rule, we can write the following:

$$p(X_1,X_2,...,X_n)=p(X_1)p(X_2|X_1)p(X_3|X_2,X_1)...p(X_n|X_{n-1},X_{n-2},...,X_2,X_1)$$

For Markov chains, it puts an assumption, called Markov assumption: The random variable at the next time step only depends on the current variable. Mathematically,

$$p(X_{t+1}|X_t,X_{t-1},...,X_2,X_1)=p(X_{t+1}|X_t)$$

where, 

$$t=2, ...n$$

Thus, we can write the expression above as follows.

$$p(X_1,X_2,...,X_n)=p(X_1)p(X_2|X_1)p(X_3|X_2)P(X_4|X_3)...p(X_n|X_{n-1})$$


### Discrete example

Suppose that you flip a coin. You have a set of number {1,2,3,4,5}. If it is head, you increase 1 in the next number (for instance, if you are 2 now, you will be get 3 in the next). In contrast, if it is tail, you will decrease the number (e.g., 2 is now and 1 is next). If is is 5, increase 1 will lead to 1. Logically, 1 and then it is reduced by 1, leading to 5. 

 
### Continuous example

$$p(X_{t+1}| X_t=x_t)=N(x_t,1)$$

```{R}
set.seed(123)
n=100
x=numeric(n)

for(i in 2:n)
{x[i]=rnorm(1,mean=x[i-1],1)}

plot.ts(x)
```
