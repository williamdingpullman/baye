## Markov chains

### Definition

A sequence of random variable $X_1, X_2,...,X_n$, with $1, 2, ...,3$ indicating the successitve points in time. Thus, based on the chain rule, we can write the following:

$$p(X_1,X_2,...,X_n)=p(X_1)p(X_2|X_1)p(X_3|X_2,X_1)...p(X_n|X_{n-1},X_{n-2},...,X_2,X_1)$$

For Markov chains, it puts an assumption, called Markov assumption: The random variable at the next time step only depends on the current variable. Mathematically,

$$p(X_{t+1}|X_t,X_{t-1},...,X_2,X_1)=p(X_{t+1}|X_t)$$

where, 

$$t=2, ...n$$

Thus, we can write the expression above as follows.

$$p(X_1,X_2,...,X_n)=p(X_1)p(X_2|X_1)p(X_3|X_2)P(X_4|X_3)...p(X_n|X_{n-1})$$


### Discrete example

Suppose that you flip a coin. You have a set of number {1,2,3,4,5}. If it is head, you increase 1 in the next number (for instance, if you are 2 now, you will be get 3 in the next). In contrast, if it is tail, you will decrease the number (e.g., 2 is now and 1 is next). If is is 5, increase 1 will lead to 1. Logically, 1 and then it is reduced by 1, leading to 5. 



 
### Continuous example

$$p(X_{t+1}| X_t=x_t)=N(x_t,1)$$

```{R}
set.seed(123)
n=100
x=numeric(n)

for(i in 2:n)
{x[i]=rnorm(1,mean=x[i-1],1)}

plot.ts(x)
```

### Discrete example and transition matrix

For the discrete example above, we can write the following transition matrix. We know that $p(X_{t+1}=5 | X_t=4)$ can be found in the 4th row, 5th column, namely 0.5.

$$Q=\begin{bmatrix} 0 & 0.5 & 0 & 0 & 0.5 \\ 0.5 & 0 & 0.5 & 0 & 0\\ 0 & 0.5 & 0 & 0.5 & 0 \\ 0& 0 & 0.5& 0& 0.5\\ 0.5 & 0& 0 &0.5 & 0 \end{bmatrix}$$


The transition matrix is especially useful when there are mutiple steps in the chain. such as $p(X_{t+1}=5| X_t=4)$. It can be calculated as $\sum_{k=1}^{5} p(X_{t+2}=3|X_{t+1}=k)  \cdot p(X_{t+1}=k |X_t=1)$. We can use R code the impletement this. 

```{R}

Q = matrix(c(0.0, 0.5, 0.0, 0.0, 0.5,
             0.5, 0.0, 0.5, 0.0, 0.0,
             0.0, 0.5, 0.0, 0.5, 0.0,
             0.0, 0.0, 0.5, 0.0, 0.5,
             0.5, 0.0, 0.0, 0.5, 0.0), 
           nrow=5, byrow=TRUE)

(jj<-Q %*% Q)
jj[1,3]


```

### Stationary distribution

__Discrete Cases___

```{R}
Q5 = Q %*% Q %*% Q %*% Q %*% Q # h=5 steps in the future

Q5
round(Q5, 3)

```


```{R}
Q30 = Q
for (i in 2:30) {
  Q30 = Q30 %*% Q
}
round(Q30, 3) # h=30 steps in the future
```

Thus, as we can see, as the time gap gets bigger, the transition distributions appear to converge. 

```{R}
Q = matrix(c(0.0, 0.5, 0.0, 0.0, 0.5,
             0.5, 0.0, 0.5, 0.0, 0.0,
             0.0, 0.5, 0.0, 0.5, 0.0,
             0.0, 0.0, 0.5, 0.0, 0.5,
             0.5, 0.0, 0.0, 0.5, 0.0), 
           nrow=5, byrow=TRUE)
Q

c(0.2, 0.2, 0.2, 0.2, 0.2) %*% Q
```


The definition of stationary distribution of a chain:

The initial state distribution for which performing a transition will not change the probability of ending up in any given state.

For a Markov chain after many iterations, the samples can be used as a Monte Carlo sample from the stationary distribution. Thus, we can use Markov chains for Bayesian inference. In order to simulate from a complicated posterior distribution, we will set up and run a Markov chain whose stationary distribution is the posterior distribution. (Note that: stationary distribution doesn't always exist for any given Markov chain)

__Continuous Cases___

As we can see, the example shown earlier does not reach a stationary distribution. But, we can modify it to make it happen. 


$$p(X_{t+1}|X_t=x_t)=N(\phi x_t,1), -1<\phi<1$$


It will reach a stationary distribution as long as $-1<\phi<1$.

```{R}
n = 1000
x = numeric(n)
phi = -0.5

for (i in 2:n) {
  x[i] = rnorm(1, mean=phi*x[i-1], sd=1.0)
}

plot.ts(x)

hist(x, freq=FALSE)
curve(dnorm(x, mean=0.0, sd=sqrt(1.0/(1.0-phi^2))), col="red", add=TRUE)
legend("topright", legend="theoretical stationary\ndistribution", col="red", lty=1, bty="n")

```

It will reach the stationary distribution of $N(0, \frac{1}{1-\phi^2})$
